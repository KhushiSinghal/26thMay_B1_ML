{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('RowNumber',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "0    15634602  Hargrave          619    France  Female   42       2   \n",
       "1    15647311      Hill          608     Spain  Female   41       1   \n",
       "2    15619304      Onio          502    France  Female   42       8   \n",
       "3    15701354      Boni          699    France  Female   39       1   \n",
       "4    15737888  Mitchell          850     Spain  Female   43       2   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              1          1               1        101348.88   \n",
       "1   83807.86              1          0               1        112542.58   \n",
       "2  159660.80              3          1               0        113931.57   \n",
       "3       0.00              2          0               0         93826.63   \n",
       "4  125510.82              1          1               1         79084.10   \n",
       "\n",
       "   Exited  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Male']= pd.get_dummies(df['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Male</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerId   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "0    15634602  Hargrave          619    France  Female   42       2   \n",
       "1    15647311      Hill          608     Spain  Female   41       1   \n",
       "2    15619304      Onio          502    France  Female   42       8   \n",
       "3    15701354      Boni          699    France  Female   39       1   \n",
       "4    15737888  Mitchell          850     Spain  Female   43       2   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              1          1               1        101348.88   \n",
       "1   83807.86              1          0               1        112542.58   \n",
       "2  159660.80              3          1               0        113931.57   \n",
       "3       0.00              2          0               0         93826.63   \n",
       "4  125510.82              1          1               1         79084.10   \n",
       "\n",
       "   Exited  Male  France  Germany  Spain  \n",
       "0       1     0       1        0      0  \n",
       "1       0     0       0        0      1  \n",
       "2       1     0       1        0      0  \n",
       "3       0     0       1        0      0  \n",
       "4       0     0       0        0      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,df['Geography'].str.get_dummies()], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerId','Surname','Geography','Gender'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Male</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Male  France  Germany  Spain  \n",
       "0               1        101348.88       1     0       1        0      0  \n",
       "1               1        112542.58       0     0       0        0      1  \n",
       "2               0        113931.57       1     0       1        0      0  \n",
       "3               0         93826.63       0     0       1        0      0  \n",
       "4               1         79084.10       0     0       0        0      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Exited',axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(activation='relu',input_shape=(12,), units=48))\n",
    "model.add(Dense(activation='relu', units=48))\n",
    "model.add(Dense(activation='relu', units=48))\n",
    "model.add(Dense(activation='relu', units=48))\n",
    "model.add(Dense(activation='relu', units=48))\n",
    "model.add(Dense(activation = 'sigmoid', units = 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',Precision(),Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 48)                624       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 10,081\n",
      "Trainable params: 10,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "750/750 [==============================] - 21s 1ms/step - loss: 182.2669 - accuracy: 0.6839 - precision: 0.2221 - recall: 0.2243\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 18.2796 - accuracy: 0.6751 - precision: 0.1765 - recall: 0.1830\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 5.1036 - accuracy: 0.6724 - precision: 0.2153 - recall: 0.2181\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 2.0035 - accuracy: 0.6825 - precision: 0.2149 - recall: 0.2087\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 1.7232 - accuracy: 0.7177 - precision: 0.2260 - recall: 0.1791\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.7823 - precision: 0.1628 - recall: 0.0192\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5085 - accuracy: 0.7958 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5028 - accuracy: 0.7986 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7991 - precision: 0.0139 - recall: 3.6941e-04\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.7615 - accuracy: 0.7861 - precision: 0.2069 - recall: 0.0136\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7969 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.8090 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.7971 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.8041 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.7951 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7957 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7973 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7995 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.8055 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7979 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7988 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7984 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5001 - accuracy: 0.8004 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.8002 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.8021 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7909 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7969 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7893 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.8001 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7845 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.8043 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.5004 - accuracy: 0.8002 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.8028 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7979 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7963 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.8043 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.8038 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7915 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.8031 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7988 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5093 - accuracy: 0.7938 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7976 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.8029 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7940 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.4976 - accuracy: 0.8023 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.7981 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.8032 - precision: 0.0000e+00 - recall: 0.0000e+00A: 0s - loss: 0.4795 - accuracy: 0.8158 - precision: 0.0000e\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7989 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7943 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7923 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7969 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7968 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.8027 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7989 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7876 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7982 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7942 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7945 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.8011 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.8028 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7983 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7982 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.8078 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5001 - accuracy: 0.8006 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7969 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7922 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.8069 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7949 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7970 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5014 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.8003 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7946 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7973 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.7988 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.8068 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7901 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.7974 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7985 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.7929 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7982 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7901 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7900 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5114 - accuracy: 0.7924 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7924 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.8018 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7957 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.7928 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7967 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.8046 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4963 - accuracy: 0.8033 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7986 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.8004 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4960 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7980 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7944 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7997 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7990 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7985 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7970 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.8076 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7999 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.8015 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.8011 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4987 - accuracy: 0.8015 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7966 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.4999 - accuracy: 0.8006 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7932 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7954 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.7989 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4954 - accuracy: 0.8036 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.7980 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.8017 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4956 - accuracy: 0.8037 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7988 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5012 - accuracy: 0.7996 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7966 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7945 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.7991 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5182 - accuracy: 0.7871 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.8031 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.7999 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.8042 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4968 - accuracy: 0.8029 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5017 - accuracy: 0.7993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7896 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5009 - accuracy: 0.7997 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5080 - accuracy: 0.7947 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7889 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5117 - accuracy: 0.7923 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5094 - accuracy: 0.7936 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7930 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.8017 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5111 - accuracy: 0.7924 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4989 - accuracy: 0.8013 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4914 - accuracy: 0.8065 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5069 - accuracy: 0.7954 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.7952 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5073 - accuracy: 0.7952 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5028 - accuracy: 0.7986 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5077 - accuracy: 0.7949 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5118 - accuracy: 0.7921 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5015 - accuracy: 0.7994 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4949 - accuracy: 0.8041 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5017 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5035 - accuracy: 0.7980 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5114 - accuracy: 0.7921 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5003 - accuracy: 0.8004 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4995 - accuracy: 0.8009 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5003 - accuracy: 0.8003 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4987 - accuracy: 0.8014 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.8009 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5074 - accuracy: 0.7950 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4922 - accuracy: 0.8060 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5227 - accuracy: 0.7834 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7949 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5033 - accuracy: 0.7982 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.8001 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.8003 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7982 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7976 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5093 - accuracy: 0.7935 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.7991 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7970 - precision: 0.0000e+00 - recall: 0.0000e+00A: 0s - loss: 0.5053 - accuracy: 0.7965 - precision: 0.0000e+00 - recall: 0.000\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7996 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5077 - accuracy: 0.7948 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5038 - accuracy: 0.7977 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4935 - accuracy: 0.8052 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4889 - accuracy: 0.8088 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7897 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5065 - accuracy: 0.7958 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.7990 - precision: 0.0000e+00 - recall: 0.0000e+00A: 0s - loss: 0.4852 - accuracy: 0.8111 - precision: 0.0000e+00 \n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7943 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7995 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.8009 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4997 - accuracy: 0.8007 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7920 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5041 - accuracy: 0.7975 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7930 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5032 - accuracy: 0.7981 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5139 - accuracy: 0.7903 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7965 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.8040 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.8016 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.5018 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.5046 - accuracy: 0.7971 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.4906 - accuracy: 0.8070 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.5018 - accuracy: 0.7992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.5027 - accuracy: 0.7985 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(xtrain,ytrain,epochs=200,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['accuracy'])\n",
    "plt.legend(['Accuracy'])\n",
    "plt.grid()\n",
    "plt.xticks(range(1,51))\n",
    "plt.xlabel('Epochs-->')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYhklEQVR4nO3de5Cd9X3f8fd3L9IKra4IVMWyERRiLAcZwtrBkJaVL20dHIObISaBWpNxy+BpbQJpa9qp7XFdp9TjaQmYTKv6EsU40TiOE0igxKBoEbQGLMXERgiDuS9XIWslVkIraffXP37Pas/RkdizN3Z/0vs1s/M85znP5XeORp/zO9/zPL8nUkpIksrTMt0NkCSNjwEuSYUywCWpUAa4JBXKAJekQrW9mQdbsmRJWrFixYT2sWfPHgDmzp07rvnxblfqcebOnTuh91vS9NuyZcurKaWTDl/+pgb4ihUr2Lx584T20dPTA0B3d/e45se7XanH6e7ubup9lTRzRcQzR1puCUWSCmWAS1KhDHBJKtSbWgOXpPE6cOAAvb297Nu3b7qbMmU6OjpYvnw57e3tTa1vgEsqQm9vL/PmzWPFihVExHQ3Z9KllNixYwe9vb2ceuqpTW1jCUVSEfbt28eJJ554TIY3QERw4oknjukbhgEuqRjHangPG+vrKyLAN2x7mT/s+dl0N0OSZpQiArznp9v52r1PTXczJB3nOjs7p7sJdYoI8JaAIW88IUl1igjwiGBwyACXNPM89NBDnHfeeaxatYqPfvSj7Ny5E4Abb7yRlStXsmrVKi677DIA7rnnHs4++2zOPvtszjnnHF577bUJHbuI0whbIrADLmnYF/5qK4+8sHtS97nyF+bz+V9/55i3+/jHP85NN93EhRdeyOc+9zm+8IUvcMMNN3D99dfz1FNPMXv2bPr6+gD4yle+ws0338wFF1xAf38/HR0dE2pzET3w1hZLKJJmnl27dtHX18eFF14IwJo1a9i0aRMAq1at4vLLL+eWW26hrS33lS+44AKuvfZabrzxRvr6+g4tH69ieuAGuKRh4+kpv9luv/12Nm3axG233cYXv/hFtm7dynXXXcdFF13EHXfcwXnnncfdd9/NmWeeOe5jFNEDjwiGhqa7FZJUb8GCBSxatIh7770XgG9961tceOGFDA0N8dxzz7F69Wq+/OUv09fXR39/P0888QRnnXUWn/nMZ+jq6uLRRx+d0PGL6IFbQpE0E+zdu5fly5cfenzttdeybt06rrrqKvbu3ctpp53GN7/5TQYHB7niiivYtWsXKSWuueYaFi5cyGc/+1k2btxIa2srK1eu5EMf+tCE2lNEgFtCkTQTDB2lFHD//fc3LLvvvvsalt10002T2p5ySijmtyTVKSLAW6rhAYZMcUk6pIgAb60GeLGMIh3f0jGeAWN9fUUEeEvLcIBPc0MkTZuOjg527NhxzIb48HjgY7m4p4gfMYdHWLQHLh2/li9fTm9vL9u3b5/upkyZ4TvyNKuIALeEIqm9vb3pO9UcL5oqoUTENRGxNSIejog/jYiOiFgcEXdFxOPVdNGUNTIsoUjS4UYN8Ih4C/BpoCul9EtAK3AZcB2wIaV0BrChejwlLKFIUqNmf8RsA+ZERBtwAvACcDGwrnp+HXDJ5DcvO9QDtwsuSYdEM7/oRsTVwJeA14Hvp5Quj4i+lNLCmnV2ppQayigRcSVwJcDSpUvPXb9+/ZgbefczB7hl235uet8JxP49QL4zRn9//5jnx7tdqceZaXcQkTR2q1ev3pJS6jp8+ag/Yla17YuBU4E+4M8i4opmD5xSWgusBejq6krd3d3NbnrIcz94GrZt5b3nn8/Dm38AQHd3Nz09PWOeH+92pR5nPO+3pDI0U0L5APBUSml7SukA8D3gfODliFgGUE1fmapGhiUUSWrQTIA/C5wXESdETtL3A9uA24A11TprgFunponQ6oU8ktRg1BJKSumBiPgu8HfAQeBH5JJIJ/CdiPgEOeQvnapGtngWiiQ1aOpCnpTS54HPH7Z4gNwbn3LhhTyS1KCMsVAO1cCnuSGSNIMUEeCtVSvtgUvSiCICvMUSiiQ1KCLArYFLUqMiAnzkLJTpbYckzSRFBLjDyUpSoyICPDwLRZIaFBHgXsgjSY2KCPCRS+kNcEkaVkSAe0ceSWpURIAP35Fn0ASXpEOKCPDhHngzN5+QpONFEQHucLKS1KiIAPemxpLUqIgA96bGktSoiAC3hCJJjYoIcC/kkaRGRQS4oxFKUqMiAtzxwCWpUREB3upgVpLUoIgA9zRCSWpURIBbQpGkRkUEuKcRSlKjIgLc0wglqVERAR4OJytJDYoI8EM9cBNckg4pIsC9I48kNSoiwL0jjyQ1KiLAwxKKJDUoIsA9D1ySGhUR4J4HLkmNighwL6WXpEZFBLglFElqVESAt3pLNUlqUESAexqhJDUqIsCjaqUlFEka0VSAR8TCiPhuRDwaEdsi4r0RsTgi7oqIx6vpoilrpDVwSWrQbA/8D4A7U0pnAu8CtgHXARtSSmcAG6rHU6LVEookNRg1wCNiPvCPga8DpJT2p5T6gIuBddVq64BLpqqRnkYoSY0ijRKKEXE2sBZ4hNz73gJcDTyfUlpYs97OlFJDGSUirgSuBFi6dOm569evH3MjDw4l/uX39/LPz2jnfUv3A9DZ2Ul/f/+Y58e7XanH6ezsHPP7LWlmWb169ZaUUtfhy9ua2LYN+GXgUymlByLiDxhDuSSltJb8AUBXV1fq7u5udtNDBocSfP8OVqw4lc7W5wHo7u6mp6dnzPPj3a7U44zn/ZZUhmZq4L1Ab0rpgerxd8mB/nJELAOopq9MTRO9I48kHcmoAZ5Segl4LiLeXi16P7mcchuwplq2Brh1SlqId+SRpCNppoQC8Cng2xExC3gS+B1y+H8nIj4BPAtcOjVNzFrCKzElqVZTAZ5SeghoKKCTe+NvitaWsIQiSTWKuBITchnFDrgkjSgmwFvCHzElqVYxAd4aYQ1ckmoUE+AtllAkqU4xAR6WUCSpTjEB3uJZKJJUp5gAbw0DXJJqFRPgnkYoSfWKCXCvxJSkegUFuCUUSapVTIDnS+mnuxWSNHMUE+CeRihJ9YoJ8BavxJSkOsUEuCUUSapXTIBbQpGkesUEuGehSFK9ggIchoamuxWSNHMUFOD2wCWpVmEBPt2tkKSZo5wAb/FHTEmqVUyAOxqhJNUrJsAdjVCS6hUT4I5GKEn1CgpwSyiSVKucAPeWapJUp5wAD6yBS1KNggLc0QglqVYxAd5qCUWS6hQT4J5GKEn1ignwloBkD1ySDikowINBA1ySDikqwB1OVpJGFBTgDmYlSbUKCnDPQpGkWuUEeIsX8khSrXIC3B64JNUpKsDNb0ka0XSAR0RrRPwoIv66erw4Iu6KiMer6aKpa2b+EXPQGookHTKWHvjVwLaax9cBG1JKZwAbqsdTxtEIJaleUwEeEcuBi4Cv1Sy+GFhXza8DLpncptWzhCJJ9aKZy9Mj4rvAfwXmAf82pfThiOhLKS2sWWdnSqmhjBIRVwJXAixduvTc9evXj6uhX//JAA+/OsgX352v5uns7KS/v3/M8+PdrtTjdHZ2juv9ljRzrF69ektKqevw5W2jbRgRHwZeSSltiYjusR44pbQWWAvQ1dWVurvHvAsA7tzxY366+xU6O3OTu7u76enpGfP8eLcr9Tjjfb8lzXyjBjhwAfCRiPg1oAOYHxG3AC9HxLKU0osRsQx4ZSobmmvgU3kESSrLqDXwlNJ/SCktTymtAC4D/jaldAVwG7CmWm0NcOuUtRJHI5Skw03kPPDrgQ9GxOPAB6vHU8bRCCWpXjMllENSSj1ATzW/A3j/5DfpyLylmiTV80pMSSpUQQGOJRRJqlFOgHslpiTVKSfAvamxJNUpKMA9jVCSahUU4OFohJJUo5wA90pMSapTToBHnlpGkaSsoADPCW4vXJKyggI8T81vScrKCfAWe+CSVKucAK9KKOa3JGUFBXie2gOXpKygAK964Aa4JAElBvg0t0OSZoqCAjxP7YFLUlZOgHsWiiTVKSfAhy/ksYgiSUCBAW4JRZKyggI8Ty2hSFJWUIB7Fook1SonwFssoUhSrXIC3MGsJKlOQQHuaYSSVKucAPc8cEmqU06AW0KRpDoFBbg9cEmqVVCA56n3xJSkrKAA9zxwSapVXoCb4JIElBTgVUutgUtSVk6AHxqNUJIEBQa4JRRJyooLcEsokpQVFOB5an5LUlZOgDsaoSTVGTXAI+KtEbExIrZFxNaIuLpavjgi7oqIx6vpoiltqOeBS1KdZnrgB4HfSym9AzgP+NcRsRK4DtiQUjoD2FA9njIjd+QxwiUJmgjwlNKLKaW/q+ZfA7YBbwEuBtZVq60DLpmqRoKjEUrS4WIsY4tExApgE/BLwLMppYU1z+1MKTWUUSLiSuBKgKVLl567fv36cTX0yb5B/vP9+/jkysQ7F0NnZyf9/f3A2ObHu12px+ns7BzX+y1p5li9evWWlFLX4cvbmt1BRHQCfw78bkppd1Q16dGklNYCawG6urpSd3d3s4ess7i3D+7/v8zq6KCzs43u7m56enoAxjQ/3u1KPc54329JM19TZ6FERDs5vL+dUvpetfjliFhWPb8MeGVqmph5IY8k1WvmLJQAvg5sSyn995qnbgPWVPNrgFsnv3kjPAtFkuo1U0K5APgXwE8i4qFq2X8Erge+ExGfAJ4FLp2aJmYOZiVJ9UYN8JTSfcDRCt7vn9zmHJ0lFEmqV86VmMPngU9vMyRpxigowO2BS1Kt8gJ8mtshSTNFcQHupfSSlJUT4FVLzW9JysoJcG+pJkl1igtwe+CSlBUU4HnqhTySlJUT4C2ehSJJtcoJcEsoklSnoADPU0sokpSVE+CWUCSpTjEBPqs1N3Vg0AiXJCgowDvaW5nX0cauAQNckqCgAAc4ed5sA1ySKkUF+EkGuCQdUlSAnzyvgz4DXJKA4gI898CTJ4NLUmEBPn82+4dg3+B0t0SSpl9RAX7SvNkA9O2zBy5JRQX4yfM6AKyDSxLFBXjuge/ab4BLUmEBnnvgnkooSYUF+Pw5bbS1WEKRJCgswCOCBbOCvgFvrCZJRQU4wMLZwW574JJUYIB3hCUUSaLAAM8lFANckooL8KVzW9hzAF7ZvW+6myJJ06q4AD99YW7y5md2TnNLJGl6FRfgp8xvob0FNj9tgEs6vhUX4G0twWkLWtjyzM+nuymSNK2KC3CAMxa18vALuxk46I+Zko5fhQZ4C4NDiSd3eUGPpONXkQF++sJWImDjcwcY8uYOko5TRQb43Pbgmg/8Ig++NMgfbd3P0JAhLun4M6EAj4h/FhE/jYifRcR1k9WoZnzqfafz66e1s6n3IJ+77eEj3mbttX0H6N9//N6CbeBgYvtrA9PdDElTJMYbbhHRCjwGfBDoBX4I/FZK6ZGjbdPV1ZU2b948ruMN6+npAaC7u5uNGzfyZ48d4I6nDjB/FpzQHnTOncvePXsYGIQd1Z17WgNOnt8BBweYWz0PcMJR5jtOOIFXd+1h/yCctGAOgwP73nD9I82PZd2JzB/t+faOOTy7Yy8JWNI5m/lz2pp6f6OptfLAYpKa9/sfPYv3nLp4XNtGxJaUUtfhy5v7X31k7wF+llJ6sjrAeuBi4KgBPtkigkt/sZ1/dM6Z3PngNl4/mDjppHm8sv112gJ+ddXpPP/MU+waSMxZvIRnnn+Rk6vngTeYn8+e2QO0t8IJixbxwksvj7J+4/xY1p3I/NGeX3ryAs5eeIBV7ziDR1/czesHRr+RaNMf5cfnFxppQubObp30fU4kwN8CPFfzuBf4lcNXiogrgSsBli5deqgHPV79/f1A7okPzy+LJ7l0xQEAOjt307/gYJ6PXk5ZMlAt30n/nIP1z7/h/PD+dtHf2cz69fNjWXci82/4fP9+Og8+wz88aUJvuaRJsP2xH9Hz2OTucyIBfqTv0A19s5TSWmAt5BJKd3f3BA5ZX0IZz/x4tyv1OBN9vyXNXBP5EbMXeGvN4+XACxNrjiSpWRMJ8B8CZ0TEqRExC7gMuG1ymiVJGs24SygppYMR8W+AvwFagW+klLZOWsskSW9oIjVwUkp3AHdMUlskSWNQ5JWYkiQDXJKKZYBLUqHGfSn9uA4WsR14ZoK7WVJNXx3n/Hi3K/U4ryKpdKeklBouyXtTA3wyRMRmgJRS13jmx7tdqcc50vgJko4NllAkqVAGuCQVakLngU+TtZMwPxn7KO04ko4xxdXAJUmZJRRJKpQBLkmFKqYGHhHfAD4CdJAHzwpgJzAHmA0crOapnq+1D5hF4wfWcP1oeGzzoSOsM7ze0e4h9kbPjeZo2x7ejtp2JmCQ/HpnVeu2HbZuVMsHqr+fA08Cv5lS2jnOtkqaYUrqgf8R8NvAS8BJ1d9rQCfwA6APuAr4TWB7tc1/AvqBduAu8h2E9pAD7XlgN9BDDsQEPEwOunuAr1TLt1TTfcDtwOvV439fHX9vdWzIYXl+tey56jgDwAHgm9W2LwOPAjuAP6n2MVSz7u5qOhzSfdX+9ld/O4Bd1d8B8r/hwer4d1d/u6r3645qnT8BNgBv6o2nJU2tYgI8pbSJfBPlfSml/pTSa8Cz5Nfwt8CJwNeBB8i99EFgfbV5VNu+Tr4RxQnk0NsFvJ0ccgH8YbXOALCZ3JP/YbWPx4CzgE3VunuAbeQPh5eqdZ4mf6DsqZYvqvYxQA7/FmBhNR0ATiZ/azhQtSkx8oHTWrWxnXyf0bbq71XyN47hbxSJkRAfqh7PB64nf5hsAX4DWAdc0vQbLmnGK+oslIhYAfw18C7gJ8A7yGG5g3yPzgfJgXgKOTx3kkNvHjnA3ksOy7eTe+BvIQd9Gzkwd5AD9sfAqdX8LnIg7q7W2wX8AvkGFt8mh+dOYDEjAdpKfXlkR9WG9mrZwWo6XOoZLpmkqn2t1eMgB/3L5LsfDZEDfh65N95RLastAR0gB/wO8ofal4DfTSnNi4idKaVFTb/hkma0Ynrgh5lD7oFuAP6eXC5oIZdVPg8sIAf7C+SeLeSgrrWQHHzvZqQEche5lLGo2sdfVccJcmmig1xKGQS+Wi3/V+TQhFx62Q68Qg7jW2qO9ceMlEW2kz8QtpK/EfSRw3cfI/8mw/uE3FMf/kDoIIf69mr916r9vl693peqdZ+qpr9NDntJx5hSA/zPyeWKM4GVwLXV8teBa8iBmIAPk4MuMTKoUxs5LId/8Pw/5LAG+AA5EFdU2ywhl2kS8DZyqN5Cft/mk2vTXyX3dAEuIJdthgeUeoXcE07V9FVyCLeQe/mnVPtZVC2bw8i3gVnVPmaTQ7ul+ptdrffWavmCapsTqmUrqtdwO/Az4B8AT0TEsqo9ko4RJQb4cuDJlNIHyKWUbcDvk0P7IDkQZzHSg51bTWdX06Xk1/1z8o+Jv8pI4H8PWMZIb30JuZc8QK5/3wtcXj3XA/wFuaf7IPlD4RFyUO8nB/XTNe3uZuTbwN6qHZ8ih+3w3y5yr3qomn+B/GPo7qq9g8AT5HBeXT33UvX88Dr7qtf8APnbCcD/BNYAtx75LZVUomJq4BHxp8AHyb3dxMiPdnvJwbWMHMTLquWHn0pYgiFGzojZS/4waiGHcsdh6+6ulg3XwodPrRw+Y6a92t9OcjnpWeDSlNLPp/xVSHpTFBPgkqR6JZZQJEkY4JJULANckgplgEtSoQxwSSqUAa4iRMRgRDxU8zdpA3NFxIqIeHiy9ie9WYoZTlbHvddTSmdPdyNGExGzgPaU0p7pbouOffbAVbSIeDoi/ltEPFj9nV4tPyUiNkTEj6vp26rlSyPiLyLi76u/86tdtUbE/46IrRHx/YiYU63/6Yh4pNrP+qM0o9YiYGtE/K+IePeUvGipYoCrFHMOK6F8rOa53Sml95DHpbmhWvZV4I9TSqvIo0beWC2/EbgnpfQu4JfJQyUAnAHcnFJ6J/mK3t+oll8HnFPt56rRGplSepk82uVG4EsR8aPqQ2DxOF+3dFReiakiRER/SqnzCMufBt6XUnoyItqBl1JKJ0bEq8CylNKBavmLKaUlEbEdWJ5SGqjZxwrgrpTSGdXjz5DLIP8lIu4kD+H7l8BfppT6x9jut5E/TP4JcFpK6YWxv3rpyOyB61iQjjJ/tHWOZKBmfniMeICLgJuBc4EtEdEWEX9TfQv4WkT8Ss23go8M7yAiTo6I3yMPSdxKHtb35TG8JmlU/oipY8HHyHcg+hj59noA/498041vkUeQvK9avgH4JHBDRLQyMlplg4hoAd6aUtoYEfeRQ7gzpfRPD1v17JptFpBvHnImeejhX0spPT+xlycdmQGuUsyJiIdqHt+ZUho+lXB2RDxA/kb5W9WyTwPfiIh/Rx4T/neq5VcDayPiE+Se9ieBF49yzFbgliqUA/gfKaW+o6xb60ZgY7I+qSlmDVxFq2rgXSmlV0dbVzrWWAOXpELZA5ekQtkDl6RCGeCSVCgDXJIKZYBLUqEMcEkq1P8Hfri8fFFgEhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.legend(['Loss'])\n",
    "plt.grid()\n",
    "plt.xticks(range(1,51))\n",
    "plt.xlabel('Epochs-->')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
